{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PostgreSQL Hacker Helper This is a VS Code extension to assist PostgreSQL Hackers - source code developers. Table of contents Configuration","title":"Home"},{"location":"#postgresql-hacker-helper","text":"This is a VS Code extension to assist PostgreSQL Hackers - source code developers.","title":"PostgreSQL Hacker Helper"},{"location":"#table-of-contents","text":"Configuration","title":"Table of contents"},{"location":"configuration/","text":"Configuration Extension has multiple settings to customize different aspects. VS Code settings There are 3 settings: postgresql-hacker-helper.logLevel - minimum log level (for old VS Code up to 1.74.0). Minimum level of log messages. By default - INFO . If using VS Code 1.74.0 ang greater use Output channel logger settings. postgresql-hacker-helper.srcPath - Path to source code directory Relative path to custom PostgreSQL source code directory. Use it, if source code files are not in your workspace root (i.e. in ${workspaceFolder}/postgresql ). Used for searching files (node tag files, pg_bsd_indent and so on). If not specified search starts from workspace root. postgresql-hacker-helper.pg_bsd_indentPath - Path to pg_bsd_indent Path to pg_bsd_indent tool. Required for formatting support. Use it if you have pg_bsd_indent installed globally or want to use specific version. If not specified, it will be searched in *srcPath*/src/tools directory. If specified, and failed to run extension will try to build it. Configuration file Extension has config file with custom settings - .vscode/pgsql_hacker_helper.json . You can create file manually or using command PgSQL: Open or create configuration file . Json schema will assist you while editing. Extension tracks changes in the file and rereads it, when necessary. Also, you can run PgSQL: Refresh configuration file command. NOTE: after debug session have started changes in configuration file will not be reflected. Arrays { \"arrays\": [ { // struct name without any qualifiers (const, volatile, etc...) \"typeName\": \"string\", // name of member in that struct, storing array \"memberName\": \"string\", // expression to evaluate to get length \"lengthExpression\": \"string\" } ] } In PostgreSQL arrays can be stored in List * variables or as simple C-arrays: struct member storing pointer and another member storing it's length. For given struct... struct Sample { /* Array */ int *array; /* Length of array */ int size; } ...we have next configuration entry: { \"arrays\": [ { \"typeName\": \"Sample\", \"memberName\": \"array\", \"lengthExpression\": \"size\" } ] } Length expression can be in 2 forms: Member name concatenated to parent object. In such case lengthExpression is just concatenated to parent object as parent->lengthExpression . As it is concatenated, then you can add some other expressions to it. Example above: size will be evaluated as ((Sample *)0xFFFF)->size Generic expression (starts with ! ) lengthExpression represents arbitrary expression which must be evaluated to some number (integer). This expression starts with ! to distinguish between this form and member name form. Example above: !{}->size will be evaluated as ((ParentType)0xFFFF)->size NOTES: You can refer to parent object using {} , i.e. !{}->member1 + {}->member2 or the same in member form member1 + {}->member2 . Expression can contain any other entries, i.e. for PlannerInfo->simple_rel_array expression is simple_rel_array_size + 1 . Aliases ( typedef ) { \"aliases\": [ { // Name of alias \"alias\": \"string\", // Actual type \"type\": \"string\" } ] } There are many typedef s in code and some of them may be for Node types. But, when resolving type, extension can not know that it is actually a typedef, so treat variable as simple, not Node derived. For such cases \"aliases\" field exists. It is array which defines aliases for different Node types - when we can not find suitable NodeTag for type we search alias and substitute type. Example: typedef Bitmapset *Relids - there is no T_Relids in the code, but T_Bitmapset exist. For it you can use this entry: { \"aliases\": [ { \"alias\": \"Relids\", \"type\": \"Bitmapset *\" } ] } Custom List * pointer types { \"customListTypes\": [ { // Struct or function name containing this 'List *' variable \"parent\": \"string\", // Name of member/variable inside \"parent\" \"member\": \"string\", // Actual pointer type \"type\": \"string\" } ] } Usually, List * contains Node types, but actually it can contain any pointer. Extension treats all List as they contain Node variables, but some lists contain non-Node types. You can specify your own custom types using customListTypes member. For this code... typedef struct SampleData { int value; } SampleData; typedef struct Sample { // Contains SampleData List *data; } Sample; void do_work() { List *list; SampleData *data; data = palloc(sizeof(SampleData)); data->value = 1; list = list_make1(data); /* ... */ } ...you can define this configuration: { \"customListTypes\": [ { \"type\": \"SampleData *\", // Member of struct \"parent\": \"Sample\", \"member\": \"data\" }, { \"type\": \"SampleData *\", // Variable inside function \"parent\": \"create_sample\", \"member\": \"list\" } ] } As you can mention, configuration is generalized, because it's clear from context how to handle parent HashTable entries HTAB { \"htab\": [ { // Struct or function name containing this HTAB \"parent\": \"string\", // Member/variable name inside parent \"member\": \"string\", // Stored type \"type\": \"string\" } ] } HTAB * Hash Table entries can be showed using hash_seq_search , but it returns void * - no information about it's type. Extension has built-in types for some HTAB s. For the following code... typedef struct SampleData { int value; } SampleData; typedef struct Sample { HTAB *data; } Sample; void do_work() { HTAB *htab = create_htab(); Sample *sample = palloc(sizeof(Sample)); sample->data = htab; /* ... */ } ...you can define next configuration: { \"htab\": [ { \"parent\": \"Sample\", \"member\": \"data\", \"type\": \"SampleData *\" }, { \"parent\": \"do_work\", \"member\": \"htab\", \"type\": \"SampleData *\" } ] } You can notice that configuration entry schema is the same as for custom List * type. _hash - simplehash { \"simplehash\": [ { // Prefix as you defined using SH_PREFIX \"prefix\": \"string\", // Stored type \"type\": \"string\" } ] } Also, there is support for lib/simplehash.h hash tables (\"simplehash\" further). They are code generated using macros, so for each specific hash table there are functions and structures defined. For the following code... typedef struct SimpleHashEntry { int value; } SimpleHashEntry; #define SH_PREFIX custom_prefix #define SH_ELEMENT_TYPE SimpleHashEntry #include \"lib/simplehash.h\" ...define next configuration: { \"simplehash\": [ { \"prefix\": \"custom_prefix\", \"type\": \"SimpleHashEntry *\" } ] } Identifiers of structures and functions are derived from prefix and generated the same way, i.e. PREFIX_iterator - structure-state for iterator. NOTE: compiler can apply unused symbol stripping, so after compilation there can be no structures/functions for iteration. In such situation, you should add some code that uses PREFIX_iterator , PREFIX_start_iterate and PREFIX_iterate (i.e. wrap such code with debug macros). Integer enum fields { \"enums\": [ { // Name of struct \"type\": \"string\", // Member of struct containing enum \"member\": \"string\", // Enum values stored in field: pair of macro name and declared value \"flags\": [ [\"Mask (macro)\", \"Mask (integer)\"], ], // Fields stored in field, values for which is got using bitmask \"fields\": [ [\"Field name\", \"Mask (macro)\", \"Mask (integer)\"] ] } ] } Some types may work with enums as plain uint32 (not enum ) and members of enum are defined using preprocessor's #define . For such types you can specify your own enum bitmask members. For the following code... typedef struct ParentType { int enum_member; } ParentType; /* Enum values */ #define EM_NOTHING 0x10 #define EM_SINGLE 0x20 #define EM_MULTIPLE 0x40 /* Mask to get length */ #define EM_LENGTH_MASK 0xF void some_function(ParentType *parent) { if (parent->enum_member & EM_MULTIPLE) { int length = parent->enum_member & EM_LENGTH_MASK; } } ...you can use configuration: { \"enums\": [ { \"type\": \"ParentType\", \"member\": \"enum_member\", \"flags\": [ [\"EM_NOTHING\", \"0x10\"], [\"EM_SINGLE\", \"0x20\"], [\"EM_MULTIPLE\", \"0x40\"], ], \"fields\": [ [\"length\", \"EM_LENGTH_MASK\", \"0xF\"] ] } ] } NOTE: macro definitions are added to debug symbols only when using -g3 level during compilation, otherwise debugger can not use macro names. If debugger can not use macros it will switch to numeric values - that because numeric values are required. NodeTags { // Array of custom NodeTag values \"nodetags\": [ \"string\" ] } NodeTag values are required to find Node types. Extension ships with set of builtin tags, but they can be outdated or you are created new Node type. If so, just add them to this list. If you specify type with T_ prefix - it will be trimmed. Also, when debug session starts, extension will parse nodetags.h file to find new NodeTags. If it will find some, then extension will automatically add them to this list. Custom typedefs.list { \"typedefs\": [ \"/path/to/typedefs.list\" ] } For formatting src/tools/pgindent is used. It requires typedefs.list file for correct work - one lies inside directory itself, but when you are developing extension you may have your own copy for extension's types. typedefs setting contains list of typedefs.list files - each string is a path which can be in 2 forms: Absolute - specified file is used Relative - file with base folder as postgresql-hacker-helper.srcPath is used Example: { \"typedefs\": [ \"contrib/pgext1/first.typedefs.list\", \"contrib/pgext2/second.typedefs.list\" ] } For convenience, if you will try to format file in contrib's directory, extension will try to detect typedefs.list in it without specifying it explicitly in configuration file. I.e. if you are formatting file contrib/my_ext/my_ext.c , then extension will probe contrib/my_ext/typedefs.list . There is handy command PgSQL: Find custom typedefs.list in repository that will execute shell command to find all *typedefs.list files in repository.","title":"Configuration"},{"location":"configuration/#configuration","text":"Extension has multiple settings to customize different aspects.","title":"Configuration"},{"location":"configuration/#vs-code-settings","text":"There are 3 settings: postgresql-hacker-helper.logLevel - minimum log level (for old VS Code up to 1.74.0). Minimum level of log messages. By default - INFO . If using VS Code 1.74.0 ang greater use Output channel logger settings. postgresql-hacker-helper.srcPath - Path to source code directory Relative path to custom PostgreSQL source code directory. Use it, if source code files are not in your workspace root (i.e. in ${workspaceFolder}/postgresql ). Used for searching files (node tag files, pg_bsd_indent and so on). If not specified search starts from workspace root. postgresql-hacker-helper.pg_bsd_indentPath - Path to pg_bsd_indent Path to pg_bsd_indent tool. Required for formatting support. Use it if you have pg_bsd_indent installed globally or want to use specific version. If not specified, it will be searched in *srcPath*/src/tools directory. If specified, and failed to run extension will try to build it.","title":"VS Code settings"},{"location":"configuration/#configuration-file","text":"Extension has config file with custom settings - .vscode/pgsql_hacker_helper.json . You can create file manually or using command PgSQL: Open or create configuration file . Json schema will assist you while editing. Extension tracks changes in the file and rereads it, when necessary. Also, you can run PgSQL: Refresh configuration file command. NOTE: after debug session have started changes in configuration file will not be reflected.","title":"Configuration file"},{"location":"configuration/#arrays","text":"{ \"arrays\": [ { // struct name without any qualifiers (const, volatile, etc...) \"typeName\": \"string\", // name of member in that struct, storing array \"memberName\": \"string\", // expression to evaluate to get length \"lengthExpression\": \"string\" } ] } In PostgreSQL arrays can be stored in List * variables or as simple C-arrays: struct member storing pointer and another member storing it's length. For given struct... struct Sample { /* Array */ int *array; /* Length of array */ int size; } ...we have next configuration entry: { \"arrays\": [ { \"typeName\": \"Sample\", \"memberName\": \"array\", \"lengthExpression\": \"size\" } ] } Length expression can be in 2 forms: Member name concatenated to parent object. In such case lengthExpression is just concatenated to parent object as parent->lengthExpression . As it is concatenated, then you can add some other expressions to it. Example above: size will be evaluated as ((Sample *)0xFFFF)->size Generic expression (starts with ! ) lengthExpression represents arbitrary expression which must be evaluated to some number (integer). This expression starts with ! to distinguish between this form and member name form. Example above: !{}->size will be evaluated as ((ParentType)0xFFFF)->size NOTES: You can refer to parent object using {} , i.e. !{}->member1 + {}->member2 or the same in member form member1 + {}->member2 . Expression can contain any other entries, i.e. for PlannerInfo->simple_rel_array expression is simple_rel_array_size + 1 .","title":"Arrays"},{"location":"configuration/#aliases-typedef","text":"{ \"aliases\": [ { // Name of alias \"alias\": \"string\", // Actual type \"type\": \"string\" } ] } There are many typedef s in code and some of them may be for Node types. But, when resolving type, extension can not know that it is actually a typedef, so treat variable as simple, not Node derived. For such cases \"aliases\" field exists. It is array which defines aliases for different Node types - when we can not find suitable NodeTag for type we search alias and substitute type. Example: typedef Bitmapset *Relids - there is no T_Relids in the code, but T_Bitmapset exist. For it you can use this entry: { \"aliases\": [ { \"alias\": \"Relids\", \"type\": \"Bitmapset *\" } ] }","title":"Aliases (typedef)"},{"location":"configuration/#custom-list-pointer-types","text":"{ \"customListTypes\": [ { // Struct or function name containing this 'List *' variable \"parent\": \"string\", // Name of member/variable inside \"parent\" \"member\": \"string\", // Actual pointer type \"type\": \"string\" } ] } Usually, List * contains Node types, but actually it can contain any pointer. Extension treats all List as they contain Node variables, but some lists contain non-Node types. You can specify your own custom types using customListTypes member. For this code... typedef struct SampleData { int value; } SampleData; typedef struct Sample { // Contains SampleData List *data; } Sample; void do_work() { List *list; SampleData *data; data = palloc(sizeof(SampleData)); data->value = 1; list = list_make1(data); /* ... */ } ...you can define this configuration: { \"customListTypes\": [ { \"type\": \"SampleData *\", // Member of struct \"parent\": \"Sample\", \"member\": \"data\" }, { \"type\": \"SampleData *\", // Variable inside function \"parent\": \"create_sample\", \"member\": \"list\" } ] } As you can mention, configuration is generalized, because it's clear from context how to handle parent","title":"Custom List * pointer types"},{"location":"configuration/#hashtable-entries","text":"","title":"HashTable entries"},{"location":"configuration/#htab","text":"{ \"htab\": [ { // Struct or function name containing this HTAB \"parent\": \"string\", // Member/variable name inside parent \"member\": \"string\", // Stored type \"type\": \"string\" } ] } HTAB * Hash Table entries can be showed using hash_seq_search , but it returns void * - no information about it's type. Extension has built-in types for some HTAB s. For the following code... typedef struct SampleData { int value; } SampleData; typedef struct Sample { HTAB *data; } Sample; void do_work() { HTAB *htab = create_htab(); Sample *sample = palloc(sizeof(Sample)); sample->data = htab; /* ... */ } ...you can define next configuration: { \"htab\": [ { \"parent\": \"Sample\", \"member\": \"data\", \"type\": \"SampleData *\" }, { \"parent\": \"do_work\", \"member\": \"htab\", \"type\": \"SampleData *\" } ] } You can notice that configuration entry schema is the same as for custom List * type.","title":"HTAB"},{"location":"configuration/#_hash-simplehash","text":"{ \"simplehash\": [ { // Prefix as you defined using SH_PREFIX \"prefix\": \"string\", // Stored type \"type\": \"string\" } ] } Also, there is support for lib/simplehash.h hash tables (\"simplehash\" further). They are code generated using macros, so for each specific hash table there are functions and structures defined. For the following code... typedef struct SimpleHashEntry { int value; } SimpleHashEntry; #define SH_PREFIX custom_prefix #define SH_ELEMENT_TYPE SimpleHashEntry #include \"lib/simplehash.h\" ...define next configuration: { \"simplehash\": [ { \"prefix\": \"custom_prefix\", \"type\": \"SimpleHashEntry *\" } ] } Identifiers of structures and functions are derived from prefix and generated the same way, i.e. PREFIX_iterator - structure-state for iterator. NOTE: compiler can apply unused symbol stripping, so after compilation there can be no structures/functions for iteration. In such situation, you should add some code that uses PREFIX_iterator , PREFIX_start_iterate and PREFIX_iterate (i.e. wrap such code with debug macros).","title":"_hash - simplehash"},{"location":"configuration/#integer-enum-fields","text":"{ \"enums\": [ { // Name of struct \"type\": \"string\", // Member of struct containing enum \"member\": \"string\", // Enum values stored in field: pair of macro name and declared value \"flags\": [ [\"Mask (macro)\", \"Mask (integer)\"], ], // Fields stored in field, values for which is got using bitmask \"fields\": [ [\"Field name\", \"Mask (macro)\", \"Mask (integer)\"] ] } ] } Some types may work with enums as plain uint32 (not enum ) and members of enum are defined using preprocessor's #define . For such types you can specify your own enum bitmask members. For the following code... typedef struct ParentType { int enum_member; } ParentType; /* Enum values */ #define EM_NOTHING 0x10 #define EM_SINGLE 0x20 #define EM_MULTIPLE 0x40 /* Mask to get length */ #define EM_LENGTH_MASK 0xF void some_function(ParentType *parent) { if (parent->enum_member & EM_MULTIPLE) { int length = parent->enum_member & EM_LENGTH_MASK; } } ...you can use configuration: { \"enums\": [ { \"type\": \"ParentType\", \"member\": \"enum_member\", \"flags\": [ [\"EM_NOTHING\", \"0x10\"], [\"EM_SINGLE\", \"0x20\"], [\"EM_MULTIPLE\", \"0x40\"], ], \"fields\": [ [\"length\", \"EM_LENGTH_MASK\", \"0xF\"] ] } ] } NOTE: macro definitions are added to debug symbols only when using -g3 level during compilation, otherwise debugger can not use macro names. If debugger can not use macros it will switch to numeric values - that because numeric values are required.","title":"Integer enum fields"},{"location":"configuration/#nodetags","text":"{ // Array of custom NodeTag values \"nodetags\": [ \"string\" ] } NodeTag values are required to find Node types. Extension ships with set of builtin tags, but they can be outdated or you are created new Node type. If so, just add them to this list. If you specify type with T_ prefix - it will be trimmed. Also, when debug session starts, extension will parse nodetags.h file to find new NodeTags. If it will find some, then extension will automatically add them to this list.","title":"NodeTags"},{"location":"configuration/#custom-typedefslist","text":"{ \"typedefs\": [ \"/path/to/typedefs.list\" ] } For formatting src/tools/pgindent is used. It requires typedefs.list file for correct work - one lies inside directory itself, but when you are developing extension you may have your own copy for extension's types. typedefs setting contains list of typedefs.list files - each string is a path which can be in 2 forms: Absolute - specified file is used Relative - file with base folder as postgresql-hacker-helper.srcPath is used Example: { \"typedefs\": [ \"contrib/pgext1/first.typedefs.list\", \"contrib/pgext2/second.typedefs.list\" ] } For convenience, if you will try to format file in contrib's directory, extension will try to detect typedefs.list in it without specifying it explicitly in configuration file. I.e. if you are formatting file contrib/my_ext/my_ext.c , then extension will probe contrib/my_ext/typedefs.list . There is handy command PgSQL: Find custom typedefs.list in repository that will execute shell command to find all *typedefs.list files in repository.","title":"Custom typedefs.list"},{"location":"create_extension/","text":"Tutorial: creating extension In this tutorial we will create extension ban_sus_query . It will check that DML queries contain predicates, otherwise will just throw an error. Next, in order not to mislead up, I will use term contrib for PostgreSQL extension, and for extension for PostgreSQL Hacker Helper VS Code extension. Creating initial files PostgreSQL has infrastructure for contrib building and installation. In short, contribs have a template architecture - most parts are common for all. So, for faster contrib creation we will use command: PgSQL: Bootstrap extension . It will prompt us to bootstrap some files - choose only C sources. After that we will have our contrib files created: Initial code Query execution pipeline has 3 stages: Parse/Semantic analysis - query string parsing and resolving tables Plan - query optimization and creating execution plan Execution - actual query execution Our logic will be added to the 2 stage, because we must check real execution plan, not Query. This is because after multiple transformations query can be changed in multiple ways - predicates can be deleted or added, therefore we may get a completely different query than in the original query string. To implement that we will create hook on planner - planner_hook . Inside we will invoke actual planner and check it's output for the existence of predicates. Starter code is the following: #include \"postgres.h\" #include \"fmgr.h\" #include \"optimizer/planner.h\" #ifdef PG_MODULE_MAGIC PG_MODULE_MAGIC; #endif static planner_hook_type prev_planner_hook; void _PG_init(void); void _PG_fini(void); static bool is_sus_query(Plan *plan) { /* ... */ return false; } static PlannedStmt * ban_sus_query_planner_hook(Query *parse, const char *query_string, int cursorOptions, ParamListInfo boundParams) { PlannedStmt *stmt; if (prev_planner_hook) stmt = prev_planner_hook(parse, query_string, cursorOptions, boundParams); else stmt = standard_planner(parse, query_string, cursorOptions, boundParams); if (is_sus_query(stmt->planTree)) ereport(ERROR, (errmsg(\"DML query does not contain predicates\"))); return stmt; } void _PG_init(void) { prev_planner_hook = planner_hook; planner_hook = ban_sus_query_planner_hook; } void _PG_fini(void) { planner_hook = prev_planner_hook; } Now we are ready to add \"business-logic\", but before let's understand how such suspicious queries look like. Examine queries Suspicious query - is a DELETE/UPDATE query that does not contain predicates. One of the benefits that we are checking already planned statements is that all predicates are already optimized in a sense that boolean rules are applied. Query plan - is a tree of Plan nodes. Each Plan contains lefttree / righttree - left and right children and qual - list of predicates to apply at this node. But we must check only UPDATE/DELETE nodes, not each node, - nodes for them is ModifyTable . Thus our goal is: traverse query tree, find ModifyTable and check that it's qual is not empty But, before run sample queries to look what their queries looks like (inside) and which predicates they have. For tests we will use this setup: -- Schema CREATE TABLE tbl(x int); -- Test queries DELETE FROM tbl; DELETE FROM tbl WHERE x = 0; UPDATE tbl SET x = 1; UPDATE tbl SET x = 1 WHERE x = 0; To do this we will use our contrib - install it using make install , add to shared_preload_libraries='ban_sus_query' and put a breakpoint to return in ban_sus_query_planner_hook function. When we run first DELETE query without predicate, we will see the following: PlannedStmt contains top-level ModifyTable with empty qual list Inner SeqScan also contains empty qual list Now run DELETE query with predicate: PlannedStmt still contains empty qual list Inner SeqScan now contains qual with single element - equality predicate This is no surprise, because our ModifyTable does not apply any filtering - it just takes tuples from children (note, that by convention single-child nodes store them in lefttree ), so it's qual is empty, but filtering is applied to SeqScan - we must check this. As you can mention, extension shows all Node variables with actual types, without showing generic Plan entry. Also extension is able to show you elements of container types ( List * in this example). More than that, it renders Expr nodes (expressions) as it was in a query, so you do not have to manually check each field, trying to figure out what expression it is. In vanilla PostgreSQL you would have to evaluate 2 expressions: (first) get NodeTag and (second) cast variable to obtained NodeTag . In this example, to show stmt->planTree all you need to do is expand the tree node in variables explorer, but manually (without extension), you need to evaluate (i.e. in watch ) 2 expressions/steps: ((Node *)planTree)->type get T_ModifyTable - tag of ModifyTable node, and then (ModifyTable *)planTree - show variable with real type. Such manipulations take roughly 5 second, but, as this time accumulates, totally it can take up to 1 hour in a day - just to show variable's contents! But there is not such support for Expr variables - you will not see their representation. For this you have to dump variable to log using pprint function, which is not very convenient when you developing in IDE. Now we are ready to write some code. is_sus_query implementation I repeat, our goal is to traverse query tree, find ModifyTable and check that it's qual is not empty , but now we can refine it: Search for ModifyTable in Plan tree and check that it's children have non-empty qual list As tree traversal is a recursive function, we will use 2 recursive functions: is_sus_query - main function that traverses plan tree to find ModifyTable node, and when it finds one invokes... contains_predicates - function that checks that this Plan node contains any predicate in a query Let's start with is_sus_query . All we have to do here is to check that Plan is a ModifyTable and if so, then check that it's children contain predicates. Node type checking is a frequent operation, so extension ships with some snippets - one of them is a isaif , which expands to if(IsA()) check: When we have determined, that it is a DML operation check that it is DELETE or UPDATE, because ModifyTable is used for other operations, i.e. INSERT . This is not hard - just check operation member. static bool is_sus_query(Plan *plan) { /* ... */ ModifyTable *modify = (ModifyTable *)plan; switch (modify->operation) { case CMD_UPDATE: case CMD_DELETE: /* Check predicates */ break; default: break; } /* ... */ } And now check these operations contain predicates using contains_predicates function (will be defined further). Also, do not forget to handle recursion: call is_sus_query for children and handle end case ( NULL ). The result function looks like this: static bool is_sus_query(Plan *plan) { /* Recursion end */ if (plan == NULL) return false; if (IsA(plan, ModifyTable)) { ModifyTable *modify = (ModifyTable *)plan; switch (modify->operation) { case CMD_UPDATE: case CMD_DELETE: return !contains_predicates(modify->plan.lefttree); default: break; } } /* Handle recursion */ return is_sus_query(plan->lefttree) || is_sus_query(plan->righttree); } contains_predicates implementation Now perform actual checking of the predicates existence using contains_predicates . Inside this function we must check that given Plan contains predicates. But situation is complicated by the fact that only base Plan is given and we do not know actual query. For example this query: DELETE FROM t1 using t2 where t1.x = t2.x; Will contain JOIN in lefttree of ModifyTable : Thus we have to clarify what does contains_predicates must check. In order not to complicate things a lot, we will just find first node with any predicate. static bool contains_predicates(Plan *plan) { if (plan == NULL) return false; if (plan->qual != NIL) return true; return contains_predicates(plan->lefttree) || contains_predicates(plan->righttree); } Testing First things first - test on example queries we defined above: postgres=# delete from tbl; ERROR: DML query does not contain predicates postgres=# delete from t1 where x = 0; DELETE 0 postgres=# update tbl set x = 0; ERROR: DML query does not contain predicates postgres=# update tbl set x = 0 where x = 0; UPDATE 0 It's working as expected. Also, as we injected our contrib as the last step, we can handle more complicated cases, like: postgres=# delete from t1 where true; ERROR: DML query does not contain predicates Further improvements This is just the beginning of the contrib, because there are lot's of corner cases that are not handled. For example, if we change true to false in last query, then we still will get an ERROR . That is because the database has realized that subquery will not return anything, so replaced with \"dummy\" Plan - Result node with FALSE one-time check, so nothing will be returned: Result So far we have seen how you can quickly create new contrib using single command that will create all necessary files. To write some templated code, we used isaif snippet to quickly add check for Node type. Also, we have traversed query plan tree and saw it's nodes, without requirement to obtain NodeTag and cast to given type, which incredibly boosts performance. And like the icing on the cake we saw expression representations of predicates. For our purposes this is not a very big deal, because query contained only 1 predicate, but in large queries with dozens of different predicates it's just a lifesaver.","title":"Create extension"},{"location":"create_extension/#tutorial-creating-extension","text":"In this tutorial we will create extension ban_sus_query . It will check that DML queries contain predicates, otherwise will just throw an error. Next, in order not to mislead up, I will use term contrib for PostgreSQL extension, and for extension for PostgreSQL Hacker Helper VS Code extension.","title":"Tutorial: creating extension"},{"location":"create_extension/#creating-initial-files","text":"PostgreSQL has infrastructure for contrib building and installation. In short, contribs have a template architecture - most parts are common for all. So, for faster contrib creation we will use command: PgSQL: Bootstrap extension . It will prompt us to bootstrap some files - choose only C sources. After that we will have our contrib files created:","title":"Creating initial files"},{"location":"create_extension/#initial-code","text":"Query execution pipeline has 3 stages: Parse/Semantic analysis - query string parsing and resolving tables Plan - query optimization and creating execution plan Execution - actual query execution Our logic will be added to the 2 stage, because we must check real execution plan, not Query. This is because after multiple transformations query can be changed in multiple ways - predicates can be deleted or added, therefore we may get a completely different query than in the original query string. To implement that we will create hook on planner - planner_hook . Inside we will invoke actual planner and check it's output for the existence of predicates. Starter code is the following: #include \"postgres.h\" #include \"fmgr.h\" #include \"optimizer/planner.h\" #ifdef PG_MODULE_MAGIC PG_MODULE_MAGIC; #endif static planner_hook_type prev_planner_hook; void _PG_init(void); void _PG_fini(void); static bool is_sus_query(Plan *plan) { /* ... */ return false; } static PlannedStmt * ban_sus_query_planner_hook(Query *parse, const char *query_string, int cursorOptions, ParamListInfo boundParams) { PlannedStmt *stmt; if (prev_planner_hook) stmt = prev_planner_hook(parse, query_string, cursorOptions, boundParams); else stmt = standard_planner(parse, query_string, cursorOptions, boundParams); if (is_sus_query(stmt->planTree)) ereport(ERROR, (errmsg(\"DML query does not contain predicates\"))); return stmt; } void _PG_init(void) { prev_planner_hook = planner_hook; planner_hook = ban_sus_query_planner_hook; } void _PG_fini(void) { planner_hook = prev_planner_hook; } Now we are ready to add \"business-logic\", but before let's understand how such suspicious queries look like.","title":"Initial code"},{"location":"create_extension/#examine-queries","text":"Suspicious query - is a DELETE/UPDATE query that does not contain predicates. One of the benefits that we are checking already planned statements is that all predicates are already optimized in a sense that boolean rules are applied. Query plan - is a tree of Plan nodes. Each Plan contains lefttree / righttree - left and right children and qual - list of predicates to apply at this node. But we must check only UPDATE/DELETE nodes, not each node, - nodes for them is ModifyTable . Thus our goal is: traverse query tree, find ModifyTable and check that it's qual is not empty But, before run sample queries to look what their queries looks like (inside) and which predicates they have. For tests we will use this setup: -- Schema CREATE TABLE tbl(x int); -- Test queries DELETE FROM tbl; DELETE FROM tbl WHERE x = 0; UPDATE tbl SET x = 1; UPDATE tbl SET x = 1 WHERE x = 0; To do this we will use our contrib - install it using make install , add to shared_preload_libraries='ban_sus_query' and put a breakpoint to return in ban_sus_query_planner_hook function. When we run first DELETE query without predicate, we will see the following: PlannedStmt contains top-level ModifyTable with empty qual list Inner SeqScan also contains empty qual list Now run DELETE query with predicate: PlannedStmt still contains empty qual list Inner SeqScan now contains qual with single element - equality predicate This is no surprise, because our ModifyTable does not apply any filtering - it just takes tuples from children (note, that by convention single-child nodes store them in lefttree ), so it's qual is empty, but filtering is applied to SeqScan - we must check this. As you can mention, extension shows all Node variables with actual types, without showing generic Plan entry. Also extension is able to show you elements of container types ( List * in this example). More than that, it renders Expr nodes (expressions) as it was in a query, so you do not have to manually check each field, trying to figure out what expression it is. In vanilla PostgreSQL you would have to evaluate 2 expressions: (first) get NodeTag and (second) cast variable to obtained NodeTag . In this example, to show stmt->planTree all you need to do is expand the tree node in variables explorer, but manually (without extension), you need to evaluate (i.e. in watch ) 2 expressions/steps: ((Node *)planTree)->type get T_ModifyTable - tag of ModifyTable node, and then (ModifyTable *)planTree - show variable with real type. Such manipulations take roughly 5 second, but, as this time accumulates, totally it can take up to 1 hour in a day - just to show variable's contents! But there is not such support for Expr variables - you will not see their representation. For this you have to dump variable to log using pprint function, which is not very convenient when you developing in IDE. Now we are ready to write some code.","title":"Examine queries"},{"location":"create_extension/#is_sus_query-implementation","text":"I repeat, our goal is to traverse query tree, find ModifyTable and check that it's qual is not empty , but now we can refine it: Search for ModifyTable in Plan tree and check that it's children have non-empty qual list As tree traversal is a recursive function, we will use 2 recursive functions: is_sus_query - main function that traverses plan tree to find ModifyTable node, and when it finds one invokes... contains_predicates - function that checks that this Plan node contains any predicate in a query Let's start with is_sus_query . All we have to do here is to check that Plan is a ModifyTable and if so, then check that it's children contain predicates. Node type checking is a frequent operation, so extension ships with some snippets - one of them is a isaif , which expands to if(IsA()) check: When we have determined, that it is a DML operation check that it is DELETE or UPDATE, because ModifyTable is used for other operations, i.e. INSERT . This is not hard - just check operation member. static bool is_sus_query(Plan *plan) { /* ... */ ModifyTable *modify = (ModifyTable *)plan; switch (modify->operation) { case CMD_UPDATE: case CMD_DELETE: /* Check predicates */ break; default: break; } /* ... */ } And now check these operations contain predicates using contains_predicates function (will be defined further). Also, do not forget to handle recursion: call is_sus_query for children and handle end case ( NULL ). The result function looks like this: static bool is_sus_query(Plan *plan) { /* Recursion end */ if (plan == NULL) return false; if (IsA(plan, ModifyTable)) { ModifyTable *modify = (ModifyTable *)plan; switch (modify->operation) { case CMD_UPDATE: case CMD_DELETE: return !contains_predicates(modify->plan.lefttree); default: break; } } /* Handle recursion */ return is_sus_query(plan->lefttree) || is_sus_query(plan->righttree); }","title":"is_sus_query implementation"},{"location":"create_extension/#contains_predicates-implementation","text":"Now perform actual checking of the predicates existence using contains_predicates . Inside this function we must check that given Plan contains predicates. But situation is complicated by the fact that only base Plan is given and we do not know actual query. For example this query: DELETE FROM t1 using t2 where t1.x = t2.x; Will contain JOIN in lefttree of ModifyTable : Thus we have to clarify what does contains_predicates must check. In order not to complicate things a lot, we will just find first node with any predicate. static bool contains_predicates(Plan *plan) { if (plan == NULL) return false; if (plan->qual != NIL) return true; return contains_predicates(plan->lefttree) || contains_predicates(plan->righttree); }","title":"contains_predicates implementation"},{"location":"create_extension/#testing","text":"First things first - test on example queries we defined above: postgres=# delete from tbl; ERROR: DML query does not contain predicates postgres=# delete from t1 where x = 0; DELETE 0 postgres=# update tbl set x = 0; ERROR: DML query does not contain predicates postgres=# update tbl set x = 0 where x = 0; UPDATE 0 It's working as expected. Also, as we injected our contrib as the last step, we can handle more complicated cases, like: postgres=# delete from t1 where true; ERROR: DML query does not contain predicates","title":"Testing"},{"location":"create_extension/#further-improvements","text":"This is just the beginning of the contrib, because there are lot's of corner cases that are not handled. For example, if we change true to false in last query, then we still will get an ERROR . That is because the database has realized that subquery will not return anything, so replaced with \"dummy\" Plan - Result node with FALSE one-time check, so nothing will be returned:","title":"Further improvements"},{"location":"create_extension/#result","text":"So far we have seen how you can quickly create new contrib using single command that will create all necessary files. To write some templated code, we used isaif snippet to quickly add check for Node type. Also, we have traversed query plan tree and saw it's nodes, without requirement to obtain NodeTag and cast to given type, which incredibly boosts performance. And like the icing on the cake we saw expression representations of predicates. For our purposes this is not a very big deal, because query contained only 1 predicate, but in large queries with dozens of different predicates it's just a lifesaver.","title":"Result"}]}